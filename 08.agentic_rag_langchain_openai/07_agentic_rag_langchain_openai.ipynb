{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Agentic RAG** with LangChain and OpenAI"
      ],
      "metadata": {
        "id": "Ueui7jbkeGet"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FvvBzKTL6f9",
        "outputId": "1f454b0a-94bb-4c35-f03b-c7e31af5256c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m964.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.3/990.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.3/377.3 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.0/337.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.3/584.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install the necessary packages\n",
        "!pip install langchain -qU\n",
        "!pip install langchain-openai -qU\n",
        "!pip install langchain-community -qU\n",
        "!pip install langchain-chroma -qU\n",
        "\n",
        "!pip install duckduckgo-search -qU\n",
        "!pip install pyowm -qU\n",
        "\n",
        "!pip install langchainhub -qU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "_0hk8jC9MDjA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize OpenAI LLM"
      ],
      "metadata": {
        "id": "3H2D6t19eU6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Set OpenAI API key\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Initialize the ChatOpenAI model\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=0\n",
        ")"
      ],
      "metadata": {
        "id": "JfdcEWGBQyk8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize Embedding Model"
      ],
      "metadata": {
        "id": "eevNQcSneq9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Set OpenAI API key\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ],
      "metadata": {
        "id": "R6VmxYgAQN9J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize DuckDuckGo Search Tool"
      ],
      "metadata": {
        "id": "gFQ5Amu3ehGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "# Initialize DuckDuckGo search tool\n",
        "search_tool = DuckDuckGoSearchRun()\n",
        "\n",
        "search_tool"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WI6BfiryYK3f",
        "outputId": "794467b9-6665-484f-d91d-e2e920e51183"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DuckDuckGoSearchRun()"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize OpenWeatherMap Tool"
      ],
      "metadata": {
        "id": "3S6k0U0JeziU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import OpenWeatherMapAPIWrapper\n",
        "from langchain.agents import load_tools\n",
        "\n",
        "os.environ[\"OPENWEATHERMAP_API_KEY\"] = userdata.get('OPENWEATHERMAP_API_KEY')\n",
        "\n",
        "# Initialize OpenWeatherMap tool\n",
        "weather = OpenWeatherMapAPIWrapper()\n",
        "\n",
        "weather_tool = load_tools([\"openweathermap-api\"], llm)[0]\n",
        "\n",
        "weather_tool"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjBynGG9YMBG",
        "outputId": "dadcd410-857b-4e3a-f420-787bac1dc84c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OpenWeatherMapQueryRun(api_wrapper=OpenWeatherMapAPIWrapper(owm=<pyowm.owm.OWM - API key=************************e2c88ea1, subscription type=free, PyOWM version=(3, 3, 0)>, openweathermap_api_key=None))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize RAG Tool"
      ],
      "metadata": {
        "id": "teoVYsQoe3cL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Load PDF Document"
      ],
      "metadata": {
        "id": "8uhSKNjLe8-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf -qU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uvn66tl_QwdJ",
        "outputId": "9b8695b6-e4ee-4736-b3b2-7bcef933d5bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/295.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/295.8 kB\u001b[0m \u001b[31m958.0 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/295.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m286.7/295.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# Load the PDF document\n",
        "loader = PyPDFLoader(\"/content/codeprolk.pdf\")\n",
        "\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "o0wQ0FW2Q5NY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iinTw94OQ754",
        "outputId": "fa9a671e-3c8b-4296-a00c-af86bc269c29"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Split Documents into Chunks"
      ],
      "metadata": {
        "id": "M-eC8l9EfQ5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Initialize the text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)\n",
        "\n",
        "# Split the documents into chunks\n",
        "splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "iyF5Ro59Q94F"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Create Vector Store and Retriever"
      ],
      "metadata": {
        "id": "q_Y4HzulfYji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "# Create a vector store from the document chunks\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=embedding_model)\n",
        "\n",
        "# Create a retriever from the vector store\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "ghSmPlIHRBe4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Create Retrieval-Augmented Generation (RAG) Chain"
      ],
      "metadata": {
        "id": "q8Rqg0iSfso6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Retrieval qa chain\n",
        "rag_chain = RetrievalQA.from_chain_type(\n",
        "                                    llm=llm,\n",
        "                                    chain_type=\"stuff\",\n",
        "                                    retriever=retriever)"
      ],
      "metadata": {
        "id": "ybUfo4NVRIFE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import Tool\n",
        "\n",
        "rag_tool = Tool(\"RAG tool\",\n",
        "              func = rag_chain.run,\n",
        "              description = \"Use it to lookup information from the Veector Store\")"
      ],
      "metadata": {
        "id": "o06xmiv6YZje"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Prompt Template"
      ],
      "metadata": {
        "id": "Bknz7x-IgEAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "\n",
        "print(prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5ye7KpKSJoc",
        "outputId": "e7b2bd11-c686-48e6-ac71-e4a9062fb4b9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer the following questions as best you can. You have access to the following tools:\n",
            "\n",
            "{tools}\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [{tool_names}]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "\n",
            "Question: {input}\n",
            "Thought:{agent_scratchpad}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set prompt template\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "template= '''\n",
        "          Answer the following questions as best you can. You have access to the following tools:\n",
        "\n",
        "          {tools}\n",
        "\n",
        "          Use the following format:\n",
        "\n",
        "          Question: the input question you must answer\n",
        "          Thought: you should always think about what to do\n",
        "          Action: the action to take, should be one of [{tool_names}]. Always look first in Vector Store\n",
        "          Action Input: the input to the action\n",
        "          Observation: the result of the action\n",
        "          ... (this Thought/Action/Action Input/Observation can repeat 2 times)\n",
        "          Thought: I now know the final answer\n",
        "          Final Answer: the final answer to the original input question\n",
        "\n",
        "          Begin!\n",
        "\n",
        "          Question: {input}\n",
        "          Thought:{agent_scratchpad}\n",
        "          '''\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "GfCYtU6jSWna"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Built-in Agent"
      ],
      "metadata": {
        "id": "F3yQVbvhgeES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_react_agent\n",
        "\n",
        "# List of tools for the agent\n",
        "tools = [search_tool, weather_tool, rag_tool]\n",
        "\n",
        "# Create the agent using the LLM and the prompt template\n",
        "agent = create_react_agent(tools = tools, llm = llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "Hn21xnDjY4T_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "# Initialize the agent executor with the created agent and tools\n",
        "agent_executor = AgentExecutor(tools=tools, agent=agent, handle_parsing_errors=True, verbose=True)"
      ],
      "metadata": {
        "id": "YRhya9gmSltO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Invoke the agent executor with an example question"
      ],
      "metadata": {
        "id": "LinaH7_sgogb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent_executor.invoke({\"input\":\"courses in codeprolk\"})\n",
        "\n",
        "print(response['output'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJfQrpTjS6EM",
        "outputId": "d43faf93-e4b5-4aa4-92df-8cf2fc214584"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI should use the RAG tool to look up information about courses in Codeprolk from the Vector Store.\n",
            "Action: RAG tool\n",
            "Action Input: \"courses in Codeprolk\"\u001b[0m\u001b[38;5;200m\u001b[1;3mCodePRO LK offers a wide array of free courses presented in Sinhala, catering to various proficiency levels from beginners to intermediates. Some key courses include Python GUI – Tkinter. The platform aims to expand its offerings to cover more advanced topics like artificial intelligence, cybersecurity, and advanced data analytics in the future.\u001b[0m\u001b[32;1m\u001b[1;3mAction: RAG tool\n",
            "Action Input: \"Codeprolk courses\"\u001b[0m\u001b[38;5;200m\u001b[1;3mCodePRO LK offers a wide array of free courses presented in Sinhala, catering to various proficiency levels from beginners to intermediates. Some key courses include Python GUI – Tkinter. The platform aims to expand its offerings to cover more advanced topics like artificial intelligence, cybersecurity, and advanced data analytics in the future. Additionally, CodePRO LK engages its community through webinars, live coding sessions, hackathons, and tech talks to provide networking opportunities and practical experience.\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: CodePRO LK offers a wide array of free courses presented in Sinhala, catering to various proficiency levels from beginners to intermediates. Some key courses include Python GUI – Tkinter. The platform aims to expand its offerings to cover more advanced topics like artificial intelligence, cybersecurity, and advanced data analytics in the future. Additionally, CodePRO LK engages its community through webinars, live coding sessions, hackathons, and tech talks to provide networking opportunities and practical experience.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "CodePRO LK offers a wide array of free courses presented in Sinhala, catering to various proficiency levels from beginners to intermediates. Some key courses include Python GUI – Tkinter. The platform aims to expand its offerings to cover more advanced topics like artificial intelligence, cybersecurity, and advanced data analytics in the future. Additionally, CodePRO LK engages its community through webinars, live coding sessions, hackathons, and tech talks to provide networking opportunities and practical experience.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent_executor.invoke({\"input\": \"What's the weather in Kandy?\"})\n",
        "\n",
        "print(response['output'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s57Ur3C3Tb1A",
        "outputId": "d8f59c7d-ea7a-4543-bf6a-41fb0a35cd0e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI should use the open_weather_map tool to find out the weather in Kandy.\n",
            "Action: open_weather_map\n",
            "Action Input: Kandy\u001b[0m\u001b[33;1m\u001b[1;3mIn Kandy, the current weather is as follows:\n",
            "Detailed status: overcast clouds\n",
            "Wind speed: 3.44 m/s, direction: 245°\n",
            "Humidity: 79%\n",
            "Temperature: \n",
            "  - Current: 23.56°C\n",
            "  - High: 23.56°C\n",
            "  - Low: 23.56°C\n",
            "  - Feels like: 24.03°C\n",
            "Rain: {}\n",
            "Heat index: None\n",
            "Cloud cover: 100%\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: The current weather in Kandy is overcast clouds with a temperature of 23.56°C and 79% humidity.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The current weather in Kandy is overcast clouds with a temperature of 23.56°C and 79% humidity.\n"
          ]
        }
      ]
    }
  ]
}